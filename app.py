ìƒí’ˆëª… ìë™ ìƒì„±ê¸° (ì‹¤ì‹œê°„ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ + ìƒí’ˆìˆ˜ í•„í„° ë°˜ì˜)

import streamlit as st import pandas as pd import requests import io from datetime import datetime

âœ… ë„¤ì´ë²„ í‚¤ì›Œë“œ API ì„¤ì •

KEYWORD_API_URL = "https://api.aicodelab.mycafe24.com/jit-plugin/getKeywordSearchData" SEARCH_API_URL = "https://api.aicodept.mycafe24.com/jit-plugin/getNaverSearchResults"

âœ… ê²€ìƒ‰ëŸ‰ + ìƒí’ˆìˆ˜ í•„í„° ì ìš©í•œ í‚¤ì›Œë“œ ë¶„ì„ í•¨ìˆ˜

@st.cache_data(show_spinner=False) def fetch_filtered_keywords(keyword): try: kw_res = requests.post(KEYWORD_API_URL, json={"keyword": keyword}, timeout=10) kw_data = kw_res.json().get("keywords", []) filtered = []

for k in kw_data:
        total_search = k["PC ì›”ê°„ê²€ìƒ‰ìˆ˜"] + k["ëª¨ë°”ì¼ ì›”ê°„ê²€ìƒ‰ìˆ˜"]
        if total_search > 3000 or k["ê²½ìŸì •ë„"] != "ë‚®ìŒ":
            continue

        query = k["í‚¤ì›Œë“œ"]
        sr_res = requests.post(SEARCH_API_URL, json={"query": query}, timeout=10)
        total_items = len(sr_res.json().get("items", []))

        if total_items <= 10000:
            filtered.append(query)

    return filtered[:10]  # ìµœëŒ€ 10ê°œê¹Œì§€ë§Œ

except:
    return []

âœ… ì¶”ì²œ ìƒí’ˆëª… ìƒì„±

@st.cache_data(show_spinner=False) def generate_filtered_names(keyword): filtered_keywords = fetch_filtered_keywords(keyword) if not filtered_keywords: return ["âŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤"]

names = []
for kw in filtered_keywords:
    name = f"{kw} ë¬´ì„  ì´ˆì†Œí˜• ê°•í’ íœ´ëŒ€ìš© ì„ í’ê¸°"
    if len(name) <= 49:
        names.append(name)
    if len(names) >= 10:
        break
return names

í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜

def extract_keyword(title): for kw in ["ì†í’ê¸°", "ì„ í’ê¸°", "ë³´ëƒ‰ë°±", "í”¼í¬ë‹‰", "ìº í•‘"]: if kw in title: return kw return title.split()[0] if title else ""

âœ… UI êµ¬ì„±

st.title("ğŸ“¦ ìƒí’ˆëª… ìë™ ìƒì„±ê¸° (ì‹¤ì‹œê°„ ì¡°ê±´ í•„í„°ë§)") st.markdown("í‚¤ì›Œë“œ ì§ì ‘ ì…ë ¥ or ì—‘ì…€ ì—…ë¡œë“œ â†’ ì‹¤ì‹œê°„ í•„í„° ê¸°ë°˜ ì¶”ì²œ")

ğŸ” í‚¤ì›Œë“œ ì…ë ¥ì°½

input_keyword = st.text_input("ëŒ€í‘œ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì†í’ê¸°, ë³´ëƒ‰ë°± ë“±)") if input_keyword: st.subheader(f"'{input_keyword}' ì¶”ì²œ ìƒí’ˆëª… (49ì ì´ë‚´)") results = generate_filtered_names(input_keyword) for name in results: st.write("- ", name)

ğŸ“ ì—‘ì…€ ì—…ë¡œë“œ

uploaded_file = st.file_uploader("ë˜ëŠ”, ì—‘ì…€ ì—…ë¡œë“œ (.xlsx) â€” Aì—´: ìƒí’ˆëª…", type=["xlsx"]) if uploaded_file: df = pd.read_excel(uploaded_file) df.columns = ["ë„ë§¤ì²˜_ìƒí’ˆëª…"] df["ëŒ€í‘œí‚¤ì›Œë“œ"] = df["ë„ë§¤ì²˜_ìƒí’ˆëª…"].apply(extract_keyword) df["ì¶”ì²œ ìƒí’ˆëª…"] = df["ëŒ€í‘œí‚¤ì›Œë“œ"].apply(lambda x: "; ".join(generate_filtered_names(x)))

st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
st.dataframe(df.head(20))

output = io.BytesIO()
with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
    df.to_excel(writer, index=False, sheet_name="ì¶”ì²œê²°ê³¼")

st.download_button(
    label="ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
    data=output.getvalue(),
    file_name=f"ì¶”ì²œìƒí’ˆëª…_{datetime.today().strftime('%Y%m%d')}.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
)

